{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2b2e7fb-0f33-4ba6-b7bc-fb2d88c426b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rosha\\documents\\jupyter\\nids\\gan_venv\\gan-venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\rosha\\Documents\\Jupyter\\NIDS\\gan_venv\\gan-venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install torch torchvision\n",
    "# !{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed04761-8fe1-4402-bc2d-6c47b80908a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\Documents\\Jupyter\\NIDS\\gan_venv\\gan-venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57419ffe-da20-4970-94ef-5d18948b6d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "annotated-types           0.7.0\n",
      "anyio                     4.6.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "astunparse                1.6.3\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "certifi                   2024.8.30\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.3.2\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.0\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.5\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.1.0\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.18.0\n",
      "flatbuffers               24.3.25\n",
      "fonttools                 4.54.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2025.3.2\n",
      "gast                      0.6.0\n",
      "google-pasta              0.2.0\n",
      "grpcio                    1.66.2\n",
      "h11                       0.14.0\n",
      "h5py                      3.12.1\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.2\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.27.0\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.5\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "keras                     3.5.0\n",
      "kiwisolver                1.4.7\n",
      "libclang                  18.1.1\n",
      "Markdown                  3.7\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.2\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.2\n",
      "ml-dtypes                 0.4.1\n",
      "mpmath                    1.3.0\n",
      "namex                     0.0.8\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "nixtla                    0.6.6\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.1.1\n",
      "opt_einsum                3.4.0\n",
      "optree                    0.12.1\n",
      "orjson                    3.10.15\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "paho-mqtt                 2.0.0\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pillow                    10.4.0\n",
      "pip                       25.0.1\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.0\n",
      "prompt_toolkit            3.0.47\n",
      "protobuf                  4.25.5\n",
      "psutil                    6.0.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "pydantic                  2.10.6\n",
      "pydantic_core             2.27.2\n",
      "Pygments                  2.18.0\n",
      "pyparsing                 3.1.4\n",
      "pyswarm                   0.6\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2025.1\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.13\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "referencing               0.35.1\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.8.1\n",
      "rpds-py                   0.20.0\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.15.1\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.1.0\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.14.0\n",
      "tenacity                  9.0.0\n",
      "tensorboard               2.17.1\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorflow-intel          2.17.0\n",
      "termcolor                 2.4.0\n",
      "terminado                 0.18.1\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.3.0\n",
      "torch                     2.7.0\n",
      "torchvision               0.22.0\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "types-python-dateutil     2.9.0.20240906\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.3\n",
      "utilsforecast             0.2.11\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.8.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.4\n",
      "wheel                     0.44.0\n",
      "wrapt                     1.16.0\n",
      "zstandard                 0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc8f160-8349-4776-8f03-967154928fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a86bcd5-918c-4185-9198-0cc0f1cede74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'F:/Documents/CRCE/Project/NIDS/dataset/Edge-IIoT/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv'  # Replace with your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf0704d-f62c-4a4c-9120-692adb0d848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52c6092-7ca1-453a-8921-a6bbc3342086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_edge_iiot(filepath):\n",
    "    df = pd.read_csv(filepath, low_memory=False)\n",
    "\n",
    "    # Drop non-useful columns\n",
    "    cols_to_drop = ['Attack_type', 'frame.time']  # if present\n",
    "    for col in cols_to_drop:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=col)\n",
    "\n",
    "    # Encode 'Attack_label' separately\n",
    "    if 'Attack_label' in df.columns:\n",
    "        y = df['Attack_label'].values\n",
    "        df = df.drop(columns=['Attack_label'])\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_dict = {}\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        le_dict[col] = le\n",
    "\n",
    "    # Scale numeric features\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    # Save scaler for later inference\n",
    "    import joblib\n",
    "    joblib.dump(scaler, 'scaler.save')\n",
    "\n",
    "    return df_scaled, y, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae3f302b-e688-4a18-886f-7d7a9a651474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign samples shape: (1615643, 60)\n"
     ]
    }
   ],
   "source": [
    "# (replace 'your_edge_iiot.csv' with your actual dataset path)\n",
    "X_train, y_train, scaler = preprocess_edge_iiot(data_path)\n",
    "\n",
    "# Select only benign samples for training\n",
    "X_benign = X_train[y_train == 0]\n",
    "print(f\"Benign samples shape: {X_benign.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be18f636-5099-4def-8cd5-7d49130aaa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "input_dim = X_benign.shape[1]\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "# Device (CPU/GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create Dataloader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset = TensorDataset(torch.tensor(X_benign, dtype=torch.float32))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize Models\n",
    "generator = Generator(latent_dim, input_dim).to(device)\n",
    "discriminator = Discriminator(input_dim).to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss\n",
    "adversarial_loss = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb44d825-de22-47dc-8af5-124fbc9932a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] D loss: 0.2727 | G loss: 2.2476\n",
      "[Epoch 2/20] D loss: 0.2255 | G loss: 2.1100\n",
      "[Epoch 3/20] D loss: 0.3323 | G loss: 2.3597\n",
      "[Epoch 4/20] D loss: 0.9703 | G loss: 1.5546\n",
      "[Epoch 5/20] D loss: 0.3018 | G loss: 2.0592\n",
      "[Epoch 6/20] D loss: 0.3876 | G loss: 2.1847\n",
      "[Epoch 7/20] D loss: 0.4827 | G loss: 1.6665\n",
      "[Epoch 8/20] D loss: 0.3438 | G loss: 1.5005\n",
      "[Epoch 9/20] D loss: 0.4833 | G loss: 1.2605\n",
      "[Epoch 10/20] D loss: 0.3724 | G loss: 1.3212\n",
      "[Epoch 11/20] D loss: 0.3579 | G loss: 1.3788\n",
      "[Epoch 12/20] D loss: 0.3026 | G loss: 1.3433\n",
      "[Epoch 13/20] D loss: 0.3053 | G loss: 1.5657\n",
      "[Epoch 14/20] D loss: 0.4404 | G loss: 1.4305\n",
      "[Epoch 15/20] D loss: 0.4066 | G loss: 1.5029\n",
      "[Epoch 16/20] D loss: 0.3196 | G loss: 1.4749\n",
      "[Epoch 17/20] D loss: 0.3787 | G loss: 1.3809\n",
      "[Epoch 18/20] D loss: 0.4819 | G loss: 1.8852\n",
      "[Epoch 19/20] D loss: 0.3189 | G loss: 1.3946\n",
      "[Epoch 20/20] D loss: 0.3467 | G loss: 1.3334\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for real_samples, in dataloader:\n",
    "        real_samples = real_samples.to(device)\n",
    "        batch_size_curr = real_samples.size(0)\n",
    "\n",
    "        # Labels\n",
    "        valid = torch.ones(batch_size_curr, 1, device=device)\n",
    "        fake = torch.zeros(batch_size_curr, 1, device=device)\n",
    "\n",
    "        # Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_pred = discriminator(real_samples)\n",
    "        real_loss = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        z = torch.randn(batch_size_curr, latent_dim, device=device)\n",
    "        fake_samples = generator(z)\n",
    "        fake_pred = discriminator(fake_samples.detach())\n",
    "        fake_loss = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size_curr, latent_dim, device=device)\n",
    "        gen_samples = generator(z)\n",
    "        gen_pred = discriminator(gen_samples)\n",
    "        g_loss = adversarial_loss(gen_pred, valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{epochs}] D loss: {d_loss.item():.4f} | G loss: {g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e028aa5-579d-423f-b7c5-1441c28fa642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generator model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the Generator\n",
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "print(\"✅ Generator model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-venv",
   "language": "python",
   "name": "gan-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
