{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868b85a3-7801-4aff-a67f-216cc1d131c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7823035f-994b-45dd-8703-84b5d8be08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = 'F:/Documents/CRCE/Project/NIDS/dataset/Edge-IIoT/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv'  # Replace with your actual path\n",
    "df = pd.read_csv(training_dataset, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06576e9-5a87-420f-8300-ee0284af032d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# df.head()\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# df.loc[1615643]\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# df_filtered.loc[1788290]\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# df.columns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# df_dropped.columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mAttack_type\u001b[39m\u001b[33m'\u001b[39m].value_counts())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# df.head()\n",
    "# df.loc[1615643]\n",
    "# df_filtered.loc[1788290]\n",
    "# df.columns\n",
    "# df_dropped.columns\n",
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36eec35-6215-426e-b8c2-383f7cf08954",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e8ca46-f64d-4198-8f00-fb2c4eb6ee11",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fdf6d9-93de-4bdd-9d09-2e74bb6cdf04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        frame.time     ip.src_host    ip.dst_host  \\\n",
      "0         2021 11:44:10.081753000    192.168.0.128  192.168.0.101   \n",
      "1         2021 11:44:10.162218000    192.168.0.101  192.168.0.128   \n",
      "2         2021 11:44:10.162271000    192.168.0.128  192.168.0.101   \n",
      "3         2021 11:44:10.162641000    192.168.0.128  192.168.0.101   \n",
      "4         2021 11:44:10.166132000    192.168.0.101  192.168.0.128   \n",
      "...                            ...             ...            ...   \n",
      "2219196   2021 23:24:32.816050000   166.75.162.225  192.168.0.128   \n",
      "2219197   2021 23:24:32.816595000    70.162.34.183  192.168.0.128   \n",
      "2219198   2021 23:24:32.818043000     40.13.95.244  192.168.0.128   \n",
      "2219199   2021 23:24:32.820831000    18.132.75.125  192.168.0.128   \n",
      "2219200   2021 23:24:32.823654000    82.173.42.163  192.168.0.128   \n",
      "\n",
      "        arp.dst.proto_ipv4  arp.opcode  arp.hw.size arp.src.proto_ipv4  \\\n",
      "0                        0         0.0          0.0                  0   \n",
      "1                        0         0.0          0.0                  0   \n",
      "2                        0         0.0          0.0                  0   \n",
      "3                        0         0.0          0.0                  0   \n",
      "4                        0         0.0          0.0                  0   \n",
      "...                    ...         ...          ...                ...   \n",
      "2219196                  0         0.0          0.0                  0   \n",
      "2219197                  0         0.0          0.0                  0   \n",
      "2219198                  0         0.0          0.0                  0   \n",
      "2219199                  0         0.0          0.0                  0   \n",
      "2219200                  0         0.0          0.0                  0   \n",
      "\n",
      "         icmp.checksum  icmp.seq_le  icmp.transmit_timestamp  ...  \\\n",
      "0                  0.0          0.0                      0.0  ...   \n",
      "1                  0.0          0.0                      0.0  ...   \n",
      "2                  0.0          0.0                      0.0  ...   \n",
      "3                  0.0          0.0                      0.0  ...   \n",
      "4                  0.0          0.0                      0.0  ...   \n",
      "...                ...          ...                      ...  ...   \n",
      "2219196        31814.0      45620.0                      0.0  ...   \n",
      "2219197        27718.0      45636.0                      0.0  ...   \n",
      "2219198        18502.0      45672.0                      0.0  ...   \n",
      "2219199         1862.0      45737.0                      0.0  ...   \n",
      "2219200        50245.0      45804.0                      0.0  ...   \n",
      "\n",
      "         mqtt.proto_len mqtt.protoname                mqtt.topic  \\\n",
      "0                   0.0              0                         0   \n",
      "1                   4.0           MQTT                         0   \n",
      "2                   0.0              0                         0   \n",
      "3                   0.0              0                         0   \n",
      "4                   0.0              0  Temperature_and_Humidity   \n",
      "...                 ...            ...                       ...   \n",
      "2219196             0.0            0.0                       0.0   \n",
      "2219197             0.0            0.0                       0.0   \n",
      "2219198             0.0            0.0                       0.0   \n",
      "2219199             0.0            0.0                       0.0   \n",
      "2219200             0.0            0.0                       0.0   \n",
      "\n",
      "        mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id mbtcp.unit_id  \\\n",
      "0                  0.0      0.0       0.0            0.0           0.0   \n",
      "1                  0.0      4.0       0.0            0.0           0.0   \n",
      "2                  0.0      0.0       0.0            0.0           0.0   \n",
      "3                  0.0      0.0       0.0            0.0           0.0   \n",
      "4                 24.0      0.0       0.0            0.0           0.0   \n",
      "...                ...      ...       ...            ...           ...   \n",
      "2219196            0.0      0.0       0.0            0.0           0.0   \n",
      "2219197            0.0      0.0       0.0            0.0           0.0   \n",
      "2219198            0.0      0.0       0.0            0.0           0.0   \n",
      "2219199            0.0      0.0       0.0            0.0           0.0   \n",
      "2219200            0.0      0.0       0.0            0.0           0.0   \n",
      "\n",
      "         Attack_label  Attack_type  \n",
      "0                   0       Normal  \n",
      "1                   0       Normal  \n",
      "2                   0       Normal  \n",
      "3                   0       Normal  \n",
      "4                   0       Normal  \n",
      "...               ...          ...  \n",
      "2219196             1    DDoS_ICMP  \n",
      "2219197             1    DDoS_ICMP  \n",
      "2219198             1    DDoS_ICMP  \n",
      "2219199             1    DDoS_ICMP  \n",
      "2219200             1    DDoS_ICMP  \n",
      "\n",
      "[1904726 rows x 63 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "Normal                   1615643\n",
       "DDoS_ICMP                 116436\n",
       "Vulnerability_scanner      50110\n",
       "DDoS_TCP                   50062\n",
       "DDoS_HTTP                  49911\n",
       "Port_Scanning              22564\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a boolean mask by checking if the 'your_column_name' column\n",
    "# is equal to 'value_1' OR is equal to 'value_2'.\n",
    "attacks_to_keep=['Normal', 'Vulnerability_scanner', 'DDoS_TCP', 'DDoS_ICMP', 'Port_Scanning', 'DDoS_HTTP']\n",
    "\n",
    "# mask = (df['Attack_type'] == 'Normal') | (df['Attack_type'] == 'value_2' | (df['Attack_type'] == 'value_2')\n",
    "mask = df['Attack_type'].isin(attacks_to_keep)\n",
    "\n",
    "# Use the boolean mask to select only the rows where the condition is True.\n",
    "# df_filtered = df[mask]\n",
    "df_filtered = df[mask].copy()\n",
    "\n",
    "# Now, df_filtered contains only the rows where 'your_column_name'\n",
    "# has either 'value_1' or 'value_2'.\n",
    "\n",
    "# If you want to modify the original DataFrame 'df' in place, you can do:\n",
    "# df = df[mask]\n",
    "\n",
    "# Print the resulting DataFrame to see the filtered data.\n",
    "print(df_filtered)\n",
    "df_filtered['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b42626-43af-4c57-aab7-cd44200125af",
   "metadata": {},
   "source": [
    "#### Add time difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4948cc41-356a-41c7-beca-a22f1e2ea1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\AppData\\Local\\Temp\\ipykernel_12080\\1563165824.py:2: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_filtered['frame.time'] = pd.to_datetime(df_filtered['frame.time'], infer_datetime_format=True)\n",
      "C:\\Users\\rosha\\AppData\\Local\\Temp\\ipykernel_12080\\1563165824.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_filtered['frame.time'] = pd.to_datetime(df_filtered['frame.time'], infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  frame.time        time_difference    ip.src_host  \\\n",
      "0 2021-01-01 11:44:10.081753        0 days 00:00:00  192.168.0.128   \n",
      "1 2021-01-01 11:44:10.162218 0 days 00:00:00.080465  192.168.0.101   \n",
      "2 2021-01-01 11:44:10.162271 0 days 00:00:00.000053  192.168.0.128   \n",
      "3 2021-01-01 11:44:10.162641 0 days 00:00:00.000370  192.168.0.128   \n",
      "4 2021-01-01 11:44:10.166132 0 days 00:00:00.003491  192.168.0.101   \n",
      "\n",
      "     ip.dst_host arp.dst.proto_ipv4  arp.opcode  arp.hw.size  \\\n",
      "0  192.168.0.101                  0         0.0          0.0   \n",
      "1  192.168.0.128                  0         0.0          0.0   \n",
      "2  192.168.0.101                  0         0.0          0.0   \n",
      "3  192.168.0.101                  0         0.0          0.0   \n",
      "4  192.168.0.128                  0         0.0          0.0   \n",
      "\n",
      "  arp.src.proto_ipv4  icmp.checksum  icmp.seq_le  ...  mqtt.proto_len  \\\n",
      "0                  0            0.0          0.0  ...             0.0   \n",
      "1                  0            0.0          0.0  ...             4.0   \n",
      "2                  0            0.0          0.0  ...             0.0   \n",
      "3                  0            0.0          0.0  ...             0.0   \n",
      "4                  0            0.0          0.0  ...             0.0   \n",
      "\n",
      "   mqtt.protoname                mqtt.topic  mqtt.topic_len mqtt.ver  \\\n",
      "0               0                         0             0.0      0.0   \n",
      "1            MQTT                         0             0.0      4.0   \n",
      "2               0                         0             0.0      0.0   \n",
      "3               0                         0             0.0      0.0   \n",
      "4               0  Temperature_and_Humidity            24.0      0.0   \n",
      "\n",
      "  mbtcp.len mbtcp.trans_id mbtcp.unit_id Attack_label  Attack_type  \n",
      "0       0.0            0.0           0.0            0       Normal  \n",
      "1       0.0            0.0           0.0            0       Normal  \n",
      "2       0.0            0.0           0.0            0       Normal  \n",
      "3       0.0            0.0           0.0            0       Normal  \n",
      "4       0.0            0.0           0.0            0       Normal  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_filtered['frame.time'] = pd.to_datetime(df_filtered['frame.time'], infer_datetime_format=True)\n",
    "    time_difference = df_filtered['frame.time'].diff().fillna(pd.Timedelta(seconds=0))\n",
    "    df_filtered.insert(1, 'time_difference', time_difference)\n",
    "    print(df_filtered.head())\n",
    "except ValueError as e:\n",
    "    print(f\"Error with infer_datetime_format: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d87bc0-d50d-443e-9bd4-fe41d2573e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  frame.time  time_difference    ip.src_host    ip.dst_host  \\\n",
      "0 2021-01-01 11:44:10.081753         0.000000  192.168.0.128  192.168.0.101   \n",
      "1 2021-01-01 11:44:10.162218         0.080465  192.168.0.101  192.168.0.128   \n",
      "2 2021-01-01 11:44:10.162271         0.000053  192.168.0.128  192.168.0.101   \n",
      "3 2021-01-01 11:44:10.162641         0.000370  192.168.0.128  192.168.0.101   \n",
      "4 2021-01-01 11:44:10.166132         0.003491  192.168.0.101  192.168.0.128   \n",
      "\n",
      "  arp.dst.proto_ipv4  arp.opcode  arp.hw.size arp.src.proto_ipv4  \\\n",
      "0                  0         0.0          0.0                  0   \n",
      "1                  0         0.0          0.0                  0   \n",
      "2                  0         0.0          0.0                  0   \n",
      "3                  0         0.0          0.0                  0   \n",
      "4                  0         0.0          0.0                  0   \n",
      "\n",
      "   icmp.checksum  icmp.seq_le  ...  mqtt.proto_len  mqtt.protoname  \\\n",
      "0            0.0          0.0  ...             0.0               0   \n",
      "1            0.0          0.0  ...             4.0            MQTT   \n",
      "2            0.0          0.0  ...             0.0               0   \n",
      "3            0.0          0.0  ...             0.0               0   \n",
      "4            0.0          0.0  ...             0.0               0   \n",
      "\n",
      "                 mqtt.topic  mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id  \\\n",
      "0                         0             0.0      0.0       0.0            0.0   \n",
      "1                         0             0.0      4.0       0.0            0.0   \n",
      "2                         0             0.0      0.0       0.0            0.0   \n",
      "3                         0             0.0      0.0       0.0            0.0   \n",
      "4  Temperature_and_Humidity            24.0      0.0       0.0            0.0   \n",
      "\n",
      "  mbtcp.unit_id Attack_label  Attack_type  \n",
      "0           0.0            0       Normal  \n",
      "1           0.0            0       Normal  \n",
      "2           0.0            0       Normal  \n",
      "3           0.0            0       Normal  \n",
      "4           0.0            0       Normal  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# Assuming df_filtered is already created and the 'time_difference' column exists\n",
    "\n",
    "# Calculate the time difference in total seconds (as a float)\n",
    "seconds_difference = df_filtered['time_difference'].dt.total_seconds()\n",
    "\n",
    "# You can either replace the existing 'time_difference' column\n",
    "df_filtered['time_difference'] = seconds_difference\n",
    "\n",
    "# Or create a new column with the time difference in seconds\n",
    "# df_filtered['time_difference_seconds'] = seconds_difference\n",
    "\n",
    "# Print the head of the DataFrame to see the result\n",
    "print(df_filtered.head())\n",
    "\n",
    "# Verify the data type of the 'time_difference' column\n",
    "print(df_filtered['time_difference'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10ef7b-f01d-4064-9c11-9740256f62a9",
   "metadata": {},
   "source": [
    "#### Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a914ad12-b2a6-423d-a863-eb0a14c44dea",
   "metadata": {},
   "source": [
    "##### Zero columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffc3df0-eca8-458e-9c86-14272c5f8e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns where all values are 0:\n",
      "['icmp.unused', 'http.tls_port', 'dns.qry.type', 'mqtt.msg_decoded_as']\n"
     ]
    }
   ],
   "source": [
    "all_zero_columns = (df == 0).all()\n",
    "\n",
    "# Filter to get only the columns where the condition is True\n",
    "all_zero_columns = all_zero_columns[all_zero_columns]\n",
    "\n",
    "# Get the list of column names where all values are 0\n",
    "list_of_all_zero_columns = all_zero_columns.index.tolist()\n",
    "\n",
    "# Print the list of columns\n",
    "print(\"Columns where all values are 0:\")\n",
    "print(list_of_all_zero_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7243f058-d84c-479a-b91b-0294ec122cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping all-zero columns:\n",
      "                  frame.time    ip.src_host    ip.dst_host arp.dst.proto_ipv4  \\\n",
      "0   2021 11:44:10.081753000   192.168.0.128  192.168.0.101                  0   \n",
      "1   2021 11:44:10.162218000   192.168.0.101  192.168.0.128                  0   \n",
      "2   2021 11:44:10.162271000   192.168.0.128  192.168.0.101                  0   \n",
      "3   2021 11:44:10.162641000   192.168.0.128  192.168.0.101                  0   \n",
      "4   2021 11:44:10.166132000   192.168.0.101  192.168.0.128                  0   \n",
      "\n",
      "   arp.opcode  arp.hw.size arp.src.proto_ipv4  icmp.checksum  icmp.seq_le  \\\n",
      "0         0.0          0.0                  0            0.0          0.0   \n",
      "1         0.0          0.0                  0            0.0          0.0   \n",
      "2         0.0          0.0                  0            0.0          0.0   \n",
      "3         0.0          0.0                  0            0.0          0.0   \n",
      "4         0.0          0.0                  0            0.0          0.0   \n",
      "\n",
      "   icmp.transmit_timestamp  ... mqtt.proto_len  mqtt.protoname  \\\n",
      "0                      0.0  ...            0.0               0   \n",
      "1                      0.0  ...            4.0            MQTT   \n",
      "2                      0.0  ...            0.0               0   \n",
      "3                      0.0  ...            0.0               0   \n",
      "4                      0.0  ...            0.0               0   \n",
      "\n",
      "                 mqtt.topic mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id  \\\n",
      "0                         0            0.0      0.0       0.0            0.0   \n",
      "1                         0            0.0      4.0       0.0            0.0   \n",
      "2                         0            0.0      0.0       0.0            0.0   \n",
      "3                         0            0.0      0.0       0.0            0.0   \n",
      "4  Temperature_and_Humidity           24.0      0.0       0.0            0.0   \n",
      "\n",
      "   mbtcp.unit_id  Attack_label  Attack_type  \n",
      "0            0.0             0       Normal  \n",
      "1            0.0             0       Normal  \n",
      "2            0.0             0       Normal  \n",
      "3            0.0             0       Normal  \n",
      "4            0.0             0       Normal  \n",
      "\n",
      "[5 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "# To drop these columns:\n",
    "df_filtered.drop(columns=list_of_all_zero_columns,axis=1, inplace=True)\n",
    "print(\"\\nDataFrame after dropping all-zero columns:\")\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a223d-57ba-4d9c-a783-f5f6c8327995",
   "metadata": {},
   "source": [
    "##### Other Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3abeefb8-3007-47a0-a668-3c5ae4f49353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.time</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>http.content_length</th>\n",
       "      <th>http.request.method</th>\n",
       "      <th>http.referer</th>\n",
       "      <th>http.request.version</th>\n",
       "      <th>http.response</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.hdrflags</th>\n",
       "      <th>mqtt.len</th>\n",
       "      <th>mqtt.msgtype</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021 11:44:10.081753000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021 11:44:10.162218000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MQTT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021 11:44:10.162271000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021 11:44:10.162641000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021 11:44:10.166132000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Temperature_and_Humidity</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  frame.time  arp.opcode  arp.hw.size  icmp.checksum  \\\n",
       "0   2021 11:44:10.081753000          0.0          0.0            0.0   \n",
       "1   2021 11:44:10.162218000          0.0          0.0            0.0   \n",
       "2   2021 11:44:10.162271000          0.0          0.0            0.0   \n",
       "3   2021 11:44:10.162641000          0.0          0.0            0.0   \n",
       "4   2021 11:44:10.166132000          0.0          0.0            0.0   \n",
       "\n",
       "   icmp.seq_le  http.content_length http.request.method http.referer  \\\n",
       "0          0.0                  0.0                 0.0          0.0   \n",
       "1          0.0                  0.0                 0.0          0.0   \n",
       "2          0.0                  0.0                 0.0          0.0   \n",
       "3          0.0                  0.0                 0.0          0.0   \n",
       "4          0.0                  0.0                 0.0          0.0   \n",
       "\n",
       "  http.request.version  http.response  ...  mqtt.hdrflags  mqtt.len  \\\n",
       "0                  0.0            0.0  ...            0.0       0.0   \n",
       "1                  0.0            0.0  ...           16.0      12.0   \n",
       "2                  0.0            0.0  ...            0.0       0.0   \n",
       "3                  0.0            0.0  ...           32.0       2.0   \n",
       "4                  0.0            0.0  ...           48.0      39.0   \n",
       "\n",
       "   mqtt.msgtype  mqtt.proto_len  mqtt.protoname                mqtt.topic  \\\n",
       "0           0.0             0.0               0                         0   \n",
       "1           1.0             4.0            MQTT                         0   \n",
       "2           0.0             0.0               0                         0   \n",
       "3           2.0             0.0               0                         0   \n",
       "4           3.0             0.0               0  Temperature_and_Humidity   \n",
       "\n",
       "   mqtt.topic_len  mqtt.ver  Attack_label  Attack_type  \n",
       "0             0.0       0.0             0       Normal  \n",
       "1             0.0       4.0             0       Normal  \n",
       "2             0.0       0.0             0       Normal  \n",
       "3             0.0       0.0             0       Normal  \n",
       "4            24.0       0.0             0       Normal  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\", \"arp.dst.proto_ipv4\", \n",
    "#                  \"http.file_data\", \"http.request.full_uri\", \"icmp.transmit_timestamp\",\n",
    "#                  \"http.request.uri.query\", \"tcp.options\", \"tcp.payload\", \"tcp.srcport\",\n",
    "#                  \"tcp.dstport\", \"udp.port\", \"mqtt.msg\", 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id', 'dns.qry.name.len']\n",
    "\n",
    "drop_columns = [\"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\", \"arp.dst.proto_ipv4\", \n",
    "                 \"http.file_data\", \"http.request.full_uri\", \"icmp.transmit_timestamp\",\n",
    "                 \"http.request.uri.query\", \"tcp.options\", \"tcp.payload\", \"tcp.srcport\",\n",
    "                 \"tcp.dstport\", \"udp.port\", \"mqtt.msg\", 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id', 'dns.qry.name.len']\n",
    "\n",
    "df_dropped=df_filtered.drop(drop_columns, axis=1, inplace=False)\n",
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10575ba-3d9c-4c65-aa27-823aaec141b4",
   "metadata": {},
   "source": [
    "#### Save Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b90dd56-996e-409e-ba31-e8786844b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = df_dropped['Attack_label']\n",
    "y_type = df_dropped['Attack_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05152f4d-9a98-4e1d-85da-319473dc8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dropped.drop(['Attack_label', 'Attack_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078804b9-efb4-416e-b75c-07ca17c14b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped.shape[1]\n",
    "# X.columns\n",
    "# y_label\n",
    "# y_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40c505-eafa-49bd-bf17-dcd5839f211e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Dummy Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06db4a22-2609-4a4a-bc59-c02e57e18de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "encode_text_dummy(X,'http.request.method')\n",
    "encode_text_dummy(X,'http.referer')\n",
    "encode_text_dummy(X,\"http.request.version\")\n",
    "encode_text_dummy(X,\"dns.qry.name.len\")\n",
    "encode_text_dummy(X,\"mqtt.conack.flags\")\n",
    "encode_text_dummy(X,\"mqtt.protoname\")\n",
    "encode_text_dummy(X,\"mqtt.topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55966a41-b80d-4f30-9f82-bd4d3d5808ca",
   "metadata": {},
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b525cb74-05d0-419c-bb9a-d50c023b53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'http.request.method',\n",
    "    'http.referer',\n",
    "    'http.request.version',\n",
    "    'http.response',\n",
    "    'dns.qry.name',\n",
    "    'mqtt.protoname',\n",
    "    'mqtt.topic',\n",
    "    'mqtt.conack.flags'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8eeb36f0-0dc5-412b-b0e9-053ca7cf3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7142337-43c3-4a46-b5c1-b22db05e658f",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7de5f68-ed3b-4035-807d-0bb18cf33ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08ebfe0-c9e5-40f8-913b-18e611b4e943",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' 2021 11:44:10.081753000 '",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2120\\256061929.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m numerical_cols = X.columns[X.nunique() > \u001b[32m2\u001b[39m]  \u001b[38;5;66;03m# Likely numeric\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m     @wraps(f)\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    321\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m             return_tuple = (\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    914\u001b[39m                 )\n\u001b[32m    915\u001b[39m \n\u001b[32m    916\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    890\u001b[39m             Fitted scaler.\n\u001b[32m    891\u001b[39m         \"\"\"\n\u001b[32m    892\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    926\u001b[39m         self : object\n\u001b[32m    927\u001b[39m             Fitted scaler.\n\u001b[32m    928\u001b[39m         \"\"\"\n\u001b[32m    929\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         X = validate_data(\n\u001b[32m    931\u001b[39m             self,\n\u001b[32m    932\u001b[39m             X,\n\u001b[32m    933\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2940\u001b[39m             out = y\n\u001b[32m   2941\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2942\u001b[39m             out = X, y\n\u001b[32m   2943\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2945\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2947\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: ' 2021 11:44:10.081753000 '"
     ]
    }
   ],
   "source": [
    "numerical_cols = X.columns[X.nunique() > 2]  # Likely numeric\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088cc7e-fd06-4702-9942-9e50a470b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_type.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4922b4-2890-4ecf-b6ab-404e928d1239",
   "metadata": {},
   "source": [
    "#### Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f515c541-b571-46b4-9011-acf8f87e568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure y_label and y_type are Series with the same index as X\n",
    "X['Attack_label'] = y_label.values\n",
    "X['Attack_type'] = y_type.values\n",
    "\n",
    "# Save to CSV\n",
    "X.to_csv('edge_iiot_preprocessed.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f3f9f-52f9-4f6c-a746-24456237c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_DNN.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2e31c1a-d225-4456-bf7f-2915e6b18bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' 2021 11:44:10.081753000 '",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2120\\2546219378.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.preprocessing \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      2\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_scaled = scaler.fit_transform(X)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m     @wraps(f)\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    321\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m             return_tuple = (\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    914\u001b[39m                 )\n\u001b[32m    915\u001b[39m \n\u001b[32m    916\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    890\u001b[39m             Fitted scaler.\n\u001b[32m    891\u001b[39m         \"\"\"\n\u001b[32m    892\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    926\u001b[39m         self : object\n\u001b[32m    927\u001b[39m             Fitted scaler.\n\u001b[32m    928\u001b[39m         \"\"\"\n\u001b[32m    929\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         X = validate_data(\n\u001b[32m    931\u001b[39m             self,\n\u001b[32m    932\u001b[39m             X,\n\u001b[32m    933\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2940\u001b[39m             out = y\n\u001b[32m   2941\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2942\u001b[39m             out = X, y\n\u001b[32m   2943\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2945\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2947\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: ' 2021 11:44:10.081753000 '"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6eac0-a070-4f1f-9ac6-2dfc8051b2db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "718cc7bb-ae18-4efb-9c7c-f0ec07b3e469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \" 2021 11:44:10.081753000 \" doesn't match format \"%Y %H:%M:%S.%f\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Convert the 'frame.time' column to datetime objects, correcting the format\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_filtered[\u001b[33m'\u001b[39m\u001b[33mframe.time\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mframe.time\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mH:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mS.\u001b[39;49m\u001b[38;5;132;43;01m%f\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Calculate the time difference between consecutive rows\u001b[39;00m\n\u001b[32m      5\u001b[39m time_difference = df_filtered[\u001b[33m'\u001b[39m\u001b[33mframe.time\u001b[39m\u001b[33m'\u001b[39m].diff()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1065\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1066\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1067\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    436\u001b[39m     arg,\n\u001b[32m    437\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    442\u001b[39m )\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    445\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    446\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    457\u001b[39m     arg,\n\u001b[32m    458\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    463\u001b[39m ) -> Index:\n\u001b[32m    464\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    469\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mstrptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \" 2021 11:44:10.081753000 \" doesn't match format \"%Y %H:%M:%S.%f\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Convert the 'frame.time' column to datetime objects, correcting the format\n",
    "df_filtered['frame.time'] = pd.to_datetime(df['frame.time'], format='%Y %H:%M:%S.%f')\n",
    "\n",
    "# Calculate the time difference between consecutive rows\n",
    "time_difference = df_filtered['frame.time'].diff()\n",
    "\n",
    "# Fill the first NaN value with a Timedelta of 0\n",
    "time_difference = time_difference.fillna(pd.Timedelta(seconds=0))\n",
    "\n",
    "# Insert the 'time_difference' column as the second column\n",
    "df_filtered.insert(1, 'time_difference', time_difference)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5353fcb7-d13b-4e66-859c-e595b9368249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2021 11:44:10.081753000 \n",
      " 2021 11:54:08.542256000 \n",
      " 2021 11:44:10.162271000 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is loaded into 'df'\n",
    "print(df['frame.time'].iloc[0])\n",
    "print(df['frame.time'].iloc[9551])\n",
    "print(df['frame.time'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "861a3a2f-8765-496e-9c1f-afb9dfc41feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              frame.time    ip.src_host ip.dst_host arp.dst.proto_ipv4  \\\n",
      "1981197  153.177.200.205  192.168.0.128           0                  0   \n",
      "\n",
      "         arp.opcode  arp.hw.size arp.src.proto_ipv4  icmp.checksum  \\\n",
      "1981197         0.0          0.0                0.0            0.0   \n",
      "\n",
      "         icmp.seq_le  icmp.transmit_timestamp  ...  mqtt.proto_len  \\\n",
      "1981197          0.0                      0.0  ...             0.0   \n",
      "\n",
      "        mqtt.protoname  mqtt.topic mqtt.topic_len mqtt.ver mbtcp.len  \\\n",
      "1981197            0.0         0.0            0.0      0.0       0.0   \n",
      "\n",
      "        mbtcp.trans_id mbtcp.unit_id  Attack_label  Attack_type  \n",
      "1981197            0.0           0.0             1     DDoS_UDP  \n",
      "\n",
      "[1 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "problematic_value = \"153.177.200.205\"\n",
    "problematic_row = df_filtered[df_filtered['frame.time'] == problematic_value]\n",
    "print(problematic_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f3dd8-8d3d-4a43-a3a9-e7e3df381ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is already loaded into 'df'\n",
    "df_filtered['frame.time'] = df_filtered['frame.time'].str.strip()\n",
    "\n",
    "def convert_to_datetime(time_str):\n",
    "    try:\n",
    "        return pd.to_datetime(time_str, format='%Y %H:%M:%S.%f')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Try parsing with potential extra digits in microseconds\n",
    "            return pd.to_datetime(time_str, format='%Y %H:%M:%S.%f000') # Assuming up to 9 digits\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting '{time_str}': {e}\")\n",
    "            return pd.NaT\n",
    "\n",
    "df_filtered['frame.time'] = df_filtered['frame.time'].apply(convert_to_datetime)\n",
    "\n",
    "time_difference = df_filtered['frame.time'].diff().fillna(pd.Timedelta(seconds=0))\n",
    "df_filtered.insert(1, 'time_difference', time_difference)\n",
    "\n",
    "print(df_filtered.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adi-kernel",
   "language": "python",
   "name": "adi-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
