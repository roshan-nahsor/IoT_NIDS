{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d38bdfe-3585-4a59-a965-7aff33d5a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e53036-4c00-4348-aceb-0626bb353d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = 'edge_iiot_preprocessed.csv'  # Replace with your actual path\n",
    "df = pd.read_csv(preprocessed_dataset, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "878ca2e4-d81b-40f3-9bfb-a63533481a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_difference</th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>http.content_length</th>\n",
       "      <th>http.request.method</th>\n",
       "      <th>http.referer</th>\n",
       "      <th>http.request.version</th>\n",
       "      <th>http.response</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.hdrflags</th>\n",
       "      <th>mqtt.len</th>\n",
       "      <th>mqtt.msgtype</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>Attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219227</td>\n",
       "      <td>-0.220062</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>0.131863</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300891</td>\n",
       "      <td>-0.281368</td>\n",
       "      <td>-0.300891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.460693</td>\n",
       "      <td>-0.460680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000818</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219227</td>\n",
       "      <td>-0.220062</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>0.131863</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044291</td>\n",
       "      <td>1.180232</td>\n",
       "      <td>0.044291</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.395124</td>\n",
       "      <td>-0.460680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000308</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219227</td>\n",
       "      <td>-0.220062</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>0.131863</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300891</td>\n",
       "      <td>-0.281368</td>\n",
       "      <td>-0.300891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.460693</td>\n",
       "      <td>-0.460680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219227</td>\n",
       "      <td>-0.220062</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>0.131863</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389473</td>\n",
       "      <td>-0.037768</td>\n",
       "      <td>0.389473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.460693</td>\n",
       "      <td>-0.460680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.219227</td>\n",
       "      <td>-0.220062</td>\n",
       "      <td>-0.040216</td>\n",
       "      <td>0.131863</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>-0.005951</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734654</td>\n",
       "      <td>4.468833</td>\n",
       "      <td>0.734654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.460693</td>\n",
       "      <td>3.395354</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_difference  arp.opcode  arp.hw.size  icmp.checksum  icmp.seq_le  \\\n",
       "0        -0.000309   -0.047835          0.0      -0.219227    -0.220062   \n",
       "1         0.000818   -0.047835          0.0      -0.219227    -0.220062   \n",
       "2        -0.000308   -0.047835          0.0      -0.219227    -0.220062   \n",
       "3        -0.000304   -0.047835          0.0      -0.219227    -0.220062   \n",
       "4        -0.000260   -0.047835          0.0      -0.219227    -0.220062   \n",
       "\n",
       "   http.content_length  http.request.method  http.referer  \\\n",
       "0            -0.040216             0.131863      0.235181   \n",
       "1            -0.040216             0.131863      0.235181   \n",
       "2            -0.040216             0.131863      0.235181   \n",
       "3            -0.040216             0.131863      0.235181   \n",
       "4            -0.040216             0.131863      0.235181   \n",
       "\n",
       "   http.request.version  http.response  ...  mqtt.hdrflags  mqtt.len  \\\n",
       "0             -0.005951              0  ...      -0.300891 -0.281368   \n",
       "1             -0.005951              0  ...       0.044291  1.180232   \n",
       "2             -0.005951              0  ...      -0.300891 -0.281368   \n",
       "3             -0.005951              0  ...       0.389473 -0.037768   \n",
       "4             -0.005951              0  ...       0.734654  4.468833   \n",
       "\n",
       "   mqtt.msgtype  mqtt.proto_len  mqtt.protoname  mqtt.topic  mqtt.topic_len  \\\n",
       "0     -0.300891             0.0       -0.460693   -0.460680             0.0   \n",
       "1      0.044291             4.0        3.395124   -0.460680             0.0   \n",
       "2     -0.300891             0.0       -0.460693   -0.460680             0.0   \n",
       "3      0.389473             0.0       -0.460693   -0.460680             0.0   \n",
       "4      0.734654             0.0       -0.460693    3.395354            24.0   \n",
       "\n",
       "   mqtt.ver  Attack_label  Attack_type  \n",
       "0       0.0             0       Normal  \n",
       "1       4.0             0       Normal  \n",
       "2       0.0             0       Normal  \n",
       "3       0.0             0       Normal  \n",
       "4       0.0             0       Normal  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45e1025c-6520-471c-8841-30bc393691c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Attack_label', 'Attack_type'], axis=1)\n",
    "y = df['Attack_label']  # for binary classification (0 or 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8483dce-a340-4904-812b-dd54fdfef31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# y\n",
    "unique_values = df['Attack_label'].unique()\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19e0c8-07e1-49c6-941b-cf1c8ea83891",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c594790-c3ce-4731-887d-a42bb09ffe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "# Reshape for Conv1D: (batch_size, in_channels=1, sequence_length)\n",
    "X_tensor = X_tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d68c8-907f-4d43-b33f-9a44da02e0b9",
   "metadata": {},
   "source": [
    "#### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57a2a31b-2c59-48ae-9a6c-e5840348cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869919bb-12e1-487f-8086-907eb2172b01",
   "metadata": {},
   "source": [
    "#### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "638e7e38-48a2-4a86-b9bc-6a8974820f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee65b0d3-085b-4c67-afec-c70101a9182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to tensors and reshape: (N, 1, num_features)\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Datasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c255126-11cc-4fce-924c-449279afbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleConv1DModel(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleConv1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        conv_out_size = (input_length - 2) // 2  # Adjust based on kernel/pool\n",
    "        self.fc1 = nn.Linear(8 * conv_out_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (batch, 8, conv_out_size)\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0286b5c-3d52-4c95-a3ef-b53959a04aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = X_train.shape[1]  # number of features\n",
    "model = SimpleConv1DModel(input_length=input_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c6796-946b-42f9-b088-d532177452d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleConv1DModel(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleConv1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        conv_out_size = (input_length - 2) // 2  # Adjust based on kernel/pool\n",
    "        self.fc1 = nn.Linear(8 * conv_out_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (batch, 8, conv_out_size)\n",
    "        x = x.view(x.size(0), -1)             # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd24ec10-2a50-4029-a40f-00a4fa858dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Batch 23810/23810\n",
      "Epoch 1: Train Acc = 0.9998, Test Acc = 1.0000, Loss = 0.0011\n",
      "Epoch 2/10 - Batch 23810/23810\n",
      "Epoch 2: Train Acc = 1.0000, Test Acc = 1.0000, Loss = 0.0005\n",
      "Epoch 3/10 - Batch 13311/23810"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     24\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m running_loss += loss.item()\n\u001b[32m     28\u001b[39m all_preds.extend(torch.argmax(outputs, dim=\u001b[32m1\u001b[39m).cpu().numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\adam.py:460\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    458\u001b[39m     param.addcdiv_(exp_avg, denom)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     step = \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     bias_correction1 = \u001b[32m1\u001b[39m - beta1**step\n\u001b[32m    463\u001b[39m     bias_correction2 = \u001b[32m1\u001b[39m - beta2**step\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:106\u001b[39m, in \u001b[36m_get_value\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        print(f\"\\rEpoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{len(train_loader)}\", end=\"\")\n",
    "\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # --- Evaluation on test set ---\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_acc = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "    # Final print for this epoch\n",
    "    print(f\"\\nEpoch {epoch+1}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}, Loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd790b34-e738-4021-b31c-58e256695873",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79757bb7-8874-49fd-99e8-b8c53a1e0405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Batch 59500/59523 --> Loss: 11430.6578, Accuracy: 92.21%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     0.9160    0.9999    0.9561   1615643\n",
      "      Attack     0.9985    0.4873    0.6550    289083\n",
      "\n",
      "    accuracy                         0.9221   1904726\n",
      "   macro avg     0.9572    0.7436    0.8055   1904726\n",
      "weighted avg     0.9285    0.9221    0.9104   1904726\n",
      "\n",
      "Epoch 2/10 - Batch 21000/59523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     50\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m running_loss += loss.item()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Accuracy tracking\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\adam.py:244\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    232\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    234\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    235\u001b[39m         group,\n\u001b[32m    236\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m         state_steps,\n\u001b[32m    242\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\adam.py:876\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    874\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\optim\\adam.py:476\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    474\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class FurtherSimplifiedConv1DModel(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(FurtherSimplifiedConv1DModel, self).__init__()\n",
    "        \n",
    "        # Single Convolutional Layer with fewer filters\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, padding=1)  # Even fewer filters\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)  # Max pooling\n",
    "        \n",
    "        # Fully connected layers with fewer neurons\n",
    "        self.fc1 = nn.Linear(4 * (input_length // 2), 8)  # Smaller fully connected layer\n",
    "        self.fc2 = nn.Linear(8, 2)  # Output layer for 2 classes\n",
    "        \n",
    "        # Dropout with a higher probability to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.8)  # Increased dropout rate to 80%\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1D + MaxPool1D\n",
    "        x = x.view(x.size(0), -1)  # Flatten after pooling\n",
    "        x = torch.relu(self.fc1(x))  # Fully connected layer\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        return self.fc2(x)  # Output layer\n",
    "\n",
    "# Instantiate the model with regularization (weight decay)\n",
    "model = FurtherSimplifiedConv1DModel(input_length=X.shape[1])\n",
    "\n",
    "# Define loss and optimizer with stronger L2 regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-3)  # Increased weight decay\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop (same as before)\n",
    "num_epochs = 10\n",
    "print_interval = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy tracking\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Print progress every `print_interval` batches\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            sys.stdout.write(f\"\\rEpoch {epoch+1}/{num_epochs} - Batch {i+1}/{len(train_loader)}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # Epoch summary\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\" --> Loss: {running_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Classification report after each epoch\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Benign\", \"Attack\"], digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82fc7b-00a2-49ba-827d-747b814b343c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### High Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7afa9676-4c28-479f-9596-c402ea20434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleConv1DModelWithDropout(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleConv1DModelWithDropout, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer with Dropout\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1)  # Even fewer filters\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)  # Max pooling\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(8 * (input_length // 2), 16)  # Reduce FC size\n",
    "        self.fc2 = nn.Linear(16, 2)  # Output layer for 2 classes\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout rate of 50%\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1D + MaxPool1D\n",
    "        x = x.view(x.size(0), -1)  # Flatten after pooling\n",
    "        x = torch.relu(self.fc1(x))  # Fully connected layer\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        return self.fc2(x)  # Output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd048098-e028-457f-b8ff-e2b55a3e966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Batch 59500/59523 --> Loss: 292.9487, Accuracy: 99.81%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     0.9978    0.9999    0.9989   1615643\n",
      "      Attack     0.9996    0.9879    0.9937    289083\n",
      "\n",
      "    accuracy                         0.9981   1904726\n",
      "   macro avg     0.9987    0.9939    0.9963   1904726\n",
      "weighted avg     0.9981    0.9981    0.9981   1904726\n",
      "\n",
      "Epoch 2/10 - Batch 59500/59523 --> Loss: 139.1888, Accuracy: 99.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     0.9986    1.0000    0.9993   1615643\n",
      "      Attack     0.9999    0.9922    0.9960    289083\n",
      "\n",
      "    accuracy                         0.9988   1904726\n",
      "   macro avg     0.9993    0.9961    0.9977   1904726\n",
      "weighted avg     0.9988    0.9988    0.9988   1904726\n",
      "\n",
      "Epoch 3/10 - Batch 59500/59523 --> Loss: 130.3780, Accuracy: 99.88%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     0.9986    1.0000    0.9993   1615643\n",
      "      Attack     0.9999    0.9922    0.9960    289083\n",
      "\n",
      "    accuracy                         0.9988   1904726\n",
      "   macro avg     0.9992    0.9961    0.9976   1904726\n",
      "weighted avg     0.9988    0.9988    0.9988   1904726\n",
      "\n",
      "Epoch 4/10 - Batch 27100/59523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m outputs = model(inputs)\n\u001b[32m     24\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m optimizer.step()\n\u001b[32m     28\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model with regularization (weight decay)\n",
    "model = SimpleConv1DModelWithDropout(input_length=X.shape[1])\n",
    "\n",
    "# Define loss and optimizer with L2 regularization (weight decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Small weight decay to prevent overfitting\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "print_interval = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy tracking\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Print progress every `print_interval` batches\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            sys.stdout.write(f\"\\rEpoch {epoch+1}/{num_epochs} - Batch {i+1}/{len(train_loader)}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # Epoch summary\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\" --> Loss: {running_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Classification report after each epoch\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Benign\", \"Attack\"], digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf6e9d96-c990-4704-80f3-1967e9f007b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleConv1DModel(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(SimpleConv1DModel, self).__init__()\n",
    "        \n",
    "        # Single Convolutional Layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)  # smaller filters\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)  # Keep max pooling, but less aggressive\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * (input_length // 2), 32)  # Reduced number of neurons\n",
    "        self.fc2 = nn.Linear(32, 2)  # Output layer for 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1D + MaxPool1D\n",
    "        x = x.view(x.size(0), -1)  # Flatten after pooling\n",
    "        x = torch.relu(self.fc1(x))  # Fully connected\n",
    "        return self.fc2(x)  # Output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d35b36c-501d-46d2-af37-0aac73dfe6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Batch 59500/59523 --> Loss: 36.5066, Accuracy: 99.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     0.9999    1.0000    0.9999   1615643\n",
      "      Attack     1.0000    0.9994    0.9997    289083\n",
      "\n",
      "    accuracy                         0.9999   1904726\n",
      "   macro avg     0.9999    0.9997    0.9998   1904726\n",
      "weighted avg     0.9999    0.9999    0.9999   1904726\n",
      "\n",
      "Epoch 2/10 - Batch 59500/59523 --> Loss: 9.5794, Accuracy: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     1.0000    1.0000    1.0000   1615643\n",
      "      Attack     1.0000    1.0000    1.0000    289083\n",
      "\n",
      "    accuracy                         1.0000   1904726\n",
      "   macro avg     1.0000    1.0000    1.0000   1904726\n",
      "weighted avg     1.0000    1.0000    1.0000   1904726\n",
      "\n",
      "Epoch 3/10 - Batch 59500/59523 --> Loss: 9.7528, Accuracy: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign     1.0000    1.0000    1.0000   1615643\n",
      "      Attack     1.0000    1.0000    1.0000    289083\n",
      "\n",
      "    accuracy                         1.0000   1904726\n",
      "   macro avg     1.0000    1.0000    1.0000   1904726\n",
      "weighted avg     1.0000    1.0000    1.0000   1904726\n",
      "\n",
      "Epoch 4/10 - Batch 46060/59523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m all_preds = []\n\u001b[32m     58\u001b[39m all_labels = []\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Jupyter\\NIDS\\new_venv\\adi-venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# model = SimpleConv1DModel(input_length=X.shape[1])\n",
    "\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         # Accuracy tracking\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "#         all_preds.extend(predicted.cpu().numpy())\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#         # Print same line update\n",
    "#         sys.stdout.write(f\"\\rEpoch {epoch+1}/{num_epochs} - Batch {i+1}/{len(train_loader)}\")\n",
    "#         sys.stdout.flush()\n",
    "\n",
    "#     # Epoch summary\n",
    "#     epoch_accuracy = 100 * correct / total\n",
    "#     print(f\" --> Loss: {running_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "#     # Classification report\n",
    "#     print(classification_report(all_labels, all_preds, target_names=[\"Benign\", \"Attack\"], digits=4))\n",
    "\n",
    "# Instantiate the simpler model\n",
    "model = SimpleConv1DModel(input_length=X.shape[1])\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "print_interval = 70  # Print every 100 batches\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Accuracy tracking\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Print progress every `print_interval` batches\n",
    "        if (i + 1) % print_interval == 0:\n",
    "            sys.stdout.write(f\"\\rEpoch {epoch+1}/{num_epochs} - Batch {i+1}/{len(train_loader)}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # Epoch summary\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\" --> Loss: {running_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Classification report after each epoch\n",
    "    print(classification_report(all_labels, all_preds, target_names=[\"Benign\", \"Attack\"], digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec021a05-de54-42ca-a354-2ed9495ec0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# To evaluate accuracy or other metrics, loop over the validation data similar to the training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7857462-f970-45cf-b7c5-f48e4354c945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adi-kernel",
   "language": "python",
   "name": "adi-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
